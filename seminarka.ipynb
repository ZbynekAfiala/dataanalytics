{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import collections\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads selected columns into variable hotel_reviews and changes their data types\n",
    "hotel_reviews = pd.read_csv(\"Hotel_Reviews.csv\", \n",
    "                 index_col=False,\n",
    "                 usecols=['Hotel_Address',\n",
    "                          'Additional_Number_of_Scoring',\n",
    "                          'Average_Score',\n",
    "                          'Hotel_Name',\n",
    "                          'Reviewer_Nationality',\n",
    "                          'Negative_Review',\n",
    "                          'Positive_Review',\n",
    "                          'Reviewer_Score',\n",
    "                          'Total_Number_of_Reviews_Reviewer_Has_Given', \n",
    "                          'Tags'],\n",
    "                 dtype={'Hotel_Address':'string',\n",
    "                          'Additional_Number_of_Scoring':'float',\n",
    "                          'Average_Score':'float',\n",
    "                          'Hotel_Name':'string',\n",
    "                          'Reviewer_Nationality':'string',\n",
    "                          'Negative_Review':'string',\n",
    "                          'Positive_Review':'string',\n",
    "                          'Reviewer_Score':'float',\n",
    "                          'Total_Number_of_Reviews_Reviewer_Has_Given':'int', \n",
    "                          'Tags':'string'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves data without duplicate rows into variable df\n",
    "df = hotel_reviews.drop_duplicates()\n",
    "\n",
    "# replaces default review answer No Negative and No Positive to blank string\n",
    "df.Negative_Review = df.Negative_Review.replace('No Negative', '')\n",
    "df.Positive_Review = df.Positive_Review.replace('No Positive', '')\n",
    "\n",
    "# rounds score to 0 decimal places\n",
    "df = df.round({'Reviewer_Score':0})\n",
    "df = df.round({'Average_Score':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints basic information about cleaned dataframe\n",
    "print(df.shape)\n",
    "print(df.describe())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histograms of columns Reviewer_Score and Average_Score\n",
    "ax = sns.countplot(data = df, x = 'Reviewer_Score')\n",
    "ax = sns.countplot(data = df, x = 'Average_Score')\n",
    "\n",
    "# heatmap for reviewer and average score\n",
    "sns.heatmap(df.pivot_table(index='Reviewer_Score', columns='Average_Score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOOGLE API\n",
    "from google.cloud import language_v1\n",
    "from google.oauth2 import service_account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authentication\n",
    "creds = service_account.Credentials.from_service_account_file('./credentials.json')\n",
    "client = language_v1.LanguageServiceClient(credentials=creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of dataframe rows to work with\n",
    "df_subset = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goes through df_subset rows and saves category of positive review for each row to array\n",
    "positive_review_category_array = []\n",
    "pos_time_start = time.time()\n",
    "for i in range(df_subset):\n",
    "    text_content = df['Positive_Review'].values[i]\n",
    "    # text must consist of at least 20 words\n",
    "    if len(df['Positive_Review'].values[i].split()) > 20:\n",
    "        def sample_classify_text(text_content):\n",
    "            type_ = language_v1.Document.Type.PLAIN_TEXT\n",
    "            language = \"en\"\n",
    "            document = {\"content\": text_content, \"type_\": type_, \"language\": language}\n",
    "            response = client.classify_text(request = {'document': document})\n",
    "            return response\n",
    "        \n",
    "        response = sample_classify_text(text_content)\n",
    "        for category in response.categories:\n",
    "            positive_review_category_array.append(str(category.name))\n",
    "    if i%10 == 0:\n",
    "        print(\"positive precessed:\", i, \"/\", df_subset, \"=\", i*100/df_subset,\"%\", round(time.time() - pos_time_start), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits categories by / delimiter\n",
    "positive_review_category_array_clean = [word for line in positive_review_category_array for word in line.split('/')]\n",
    "# filters out blank strings from array\n",
    "positive_review_category_array_clean = [n for n in positive_review_category_array_clean if n != '']\n",
    "# creates dataframe of unique categories and their amount\n",
    "df_pos = pd.DataFrame.from_dict(collections.Counter(np.array(positive_review_category_array_clean)), orient='index').reset_index()\n",
    "# sorts by most frequent categories and filters first 20 rows\n",
    "df_pos.sort_values(by=0,ascending = False).head(20)\n",
    "# bar chart representation\n",
    "df_pos_chart = sns.barplot(data = df_pos.sort_values(by=0,ascending = False).head(20), y = 'index', x = 0).set_title('Top 20 categories of positive reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goes through df_subset rows and saves category of negative review for each row to array\n",
    "negative_review_category_array = []\n",
    "neg_time_start = time.time()\n",
    "for i in range(df_subset):\n",
    "    text_content = df['Negative_Review'].values[i]\n",
    "    if len(df['Negative_Review'].values[i].split()) > 20:\n",
    "        def sample_classify_text(text_content):\n",
    "            type_ = language_v1.Document.Type.PLAIN_TEXT\n",
    "            language = \"en\"\n",
    "            document = {\"content\": df['Negative_Review'].values[i], \"type_\": type_, \"language\": language}\n",
    "            response = client.classify_text(request = {'document': document})\n",
    "            return response\n",
    "        \n",
    "        response = sample_classify_text(df['Negative_Review'].values[i])\n",
    "        for category in response.categories:\n",
    "            negative_review_category_array.append(str(category.name))\n",
    "    if i%10 == 0:\n",
    "        print(\"negative precessed:\", i, \"/\", df_subset, \"=\", i*100/df_subset,\"%\", round(time.time() - neg_time_start), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits categories by / delimiter        \n",
    "negative_review_category_array_clean = [word for line in negative_review_category_array for word in line.split('/')]\n",
    "# filters out blank strings from array\n",
    "negative_review_category_array_clean = [n for n in negative_review_category_array_clean if n != '']\n",
    "# creates dataframe of unique categories and their amount\n",
    "df_neg = pd.DataFrame.from_dict(collections.Counter(np.array(negative_review_category_array_clean)), orient='index').reset_index()\n",
    "# sorts by most frequent categories and filters first 20 rows\n",
    "df_neg.sort_values(by=0,ascending = False).head(20)\n",
    "# bar chart representation\n",
    "df_neg_chart = sns.barplot(data = df_neg.sort_values(by=0,ascending = False).head(20), y = 'index', x = 0).set_title('Top 20 categories of negative reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#druha cast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soubor = pd.read_csv('C:/Users/zbyne/Downloads/hotel_reviews.csv')\n",
    "len(soubor) #515738\n",
    "soubor.head(5)\n",
    "#Latitude and longitude = Zeměpisná šířka a zeměpisná délka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soubor.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chybí nějaké hodnoty?\n",
    "soubor.isna().sum()/(len(soubor)) #ano, ale ty beztak nebudeme používat, takže to nebudeme řešit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#počet hotelů v souboru\n",
    "len(pd.unique(soubor['Hotel_Address']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#základní přehled\n",
    "soubor.groupby(['Hotel_Name']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rozložení skóre recenzí, né uplně pěkný.\n",
    "df = soubor['Reviewer_Score']\n",
    "sns.countplot(x=\"Reviewer_Score\",data=soubor,palette=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pokus o rozdělení hodnot na základě reviewer score dle hranice  0-6 negativní ...\n",
    "soubor[\"P/N\"] = pd.cut(soubor[\"Reviewer_Score\"], \n",
    "                   bins=[0,6,10], \n",
    "                   labels=[\"Negative\",\"Positive\"],right=True)\n",
    "sns.countplot(x=\"P/N\",data=soubor,palette=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = soubor[['Reviewer_Nationality','P/N']]\n",
    "subset.groupby(\"P/N\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = soubor['Hotel_Address']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extrahovani statu z adres hotelů a následné přidání států do df\n",
    "stat = soubor['Hotel_Address']\n",
    "staty = []\n",
    "\n",
    "for i in range(0,len(soubor)):\n",
    "    x = [token.text for token in nlp(stat[i])][-1]\n",
    "    if x == \"Kingdom\":\n",
    "        x = 'United Kingdom'\n",
    "    staty.append(x)\n",
    "\n",
    "soubor['stat'] = staty\n",
    "print('Transformation was successful.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kontrola\n",
    "pd.unique(soubor['stat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nejčastější podstatná jména v negativních recenzích na vzorku ze souboru; lepší/rozumnější by bylo použít pro vzorek funkci sample(n=...)\n",
    "vzorek = soubor[0:9000]\n",
    "\n",
    "vzorek_negative_review_list = list(vzorek['Negative_Review'])\n",
    "delimiter = ','\n",
    "final_str = delimiter.join(map(str, vzorek_negative_review_list))\n",
    "doc = nlp(final_str)\n",
    "nouns = [token.lemma_ for token in doc if token.is_stop != True and token.is_punct != True and token.pos_ == 'NOUN']\n",
    "word_freq = Counter(nouns)\n",
    "word_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nejčastější slovesa v negativních recenzích na vzorku prvnich 9000 ze souboru\n",
    "vzorek = soubor[0:9000]\n",
    "\n",
    "vzorek_negative_review_list = list(vzorek['Negative_Review'])\n",
    "delimiter = ','\n",
    "final_str = delimiter.join(map(str, vzorek_negative_review_list))\n",
    "doc = nlp(final_str)\n",
    "verbs = [token.lemma_ for token in doc if token.is_stop != True and token.is_punct != True and token.pos_ == 'VERB']\n",
    "word_freq = Counter(verbs)\n",
    "word_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#přídavná jména spojena s nějčastějším podst. jménem \"ROOM\"(vycházejíc ze skriptu předtím) v negativních recenzí na souboru\n",
    "\n",
    "pattern = [{'POS': 'ADJ'},{'TEXT': 'room'}]\n",
    "list1 = []\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add('ADJ_NOUN_PATTERN', None, pattern)\n",
    "\n",
    "for i in range(0,len(soubor)):\n",
    "    doc = nlp(soubor.iloc[i,6])\n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        list1.append(doc[start:end].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vytvoření funkce pro zobrazení top 5\n",
    "from collections import Counter\n",
    "def most_frequent(List):\n",
    "    List = [x.lower() for x in List]\n",
    "    occurence_count = Counter(List)\n",
    "    return occurence_count.most_common(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##přídavná jména spojena s nějčastějším podst. jménem \"ROOM\"(vycházejíc ze skriptu předtím) v negativních recenzí na souboru výsledek\n",
    "print(most_frequent(list1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#přídavná jména spojena s nějčastějšími podst. jménem \"Breakfast\" v negativních recenzí na souboru\n",
    "\n",
    "pattern = [{'POS': 'ADJ'},{'TEXT': 'breakfast'}]\n",
    "list_breakfast = []\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add('ADJ_NOUN_PATTERN', None, pattern)\n",
    "\n",
    "for i in range(0,len(soubor)):\n",
    "    doc = nlp(soubor.iloc[i,6])\n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        list_breakfast.append(doc[start:end].text)\n",
    "        \n",
    "print(most_frequent(list_breakfast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relativní počty recenzí k hotelům, resp. kolik recenzí se stahovalo k jaké zemi\n",
    "import seaborn as sns\n",
    "rel_l = []\n",
    "rel_ln = ['United Kingdom','Spain','France','Netherlands','Austria','Italy']\n",
    "for i in list(soubor['stat'].value_counts()):\n",
    "    rel = i/len(soubor)\n",
    "    rel_l.append(rel)\n",
    "temp = pd.DataFrame()\n",
    "temp['stát'] = rel_ln\n",
    "temp ['rel_pocty'] = rel_l\n",
    "temp\n",
    "sns.barplot(y='rel_pocty',x=\"stát\",data=temp,palette=\"rocket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nejčastější národnost hostů - 3\n",
    "sns.countplot(x='Reviewer_Nationality',data=soubor,palette=\"rocket\",order=soubor.Reviewer_Nationality.value_counts().iloc[:3].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#absolutní počty nejčastějších národností\n",
    "soubor['Reviewer_Nationality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kontingenční tabulka\n",
    "mask = soubor['Reviewer_Nationality'].isin([' United Kingdom ',' United States of America ', ' Australia ',' Ireland ',' United Arab Emirates ',' Slovakia ', ' Czech Republic '])\n",
    "table = soubor[mask].pivot_table(\n",
    "        values='Hotel_Address', \n",
    "        index='Reviewer_Nationality',\n",
    "        columns='stat', \n",
    "        aggfunc='count', \n",
    "        margins=True\n",
    "    )\n",
    "table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
